## Step 2 : Installing NGINX as an Ingress Controller

### 2.1. Installing the NGINX Ingress Controller

So that's **really** simple! The [NGINX Installation guide on K8S](https://kubernetes.github.io/ingress-nginx/deploy/) provides all the instructions (insanely easy). 

In this case, even if we installing K8S on Google Cloud Platform, we're **not using GKE**, so **DO NOT** install NGINX using [the GCE-GKE installation](https://kubernetes.github.io/ingress-nginx/deploy/#gce-gke), since that will actually try to provision a Google Cloud Load Balancer, which I want to avoid here.

The reason I want to avoid this Load Balancer is that even in its simplest configuration, it ends up being **pretty expensive** (around 18$ a month), which is unnecessary for simple workloads.

So to install NGINX as an Ingress Controller, follow the [Bare Metal installation instructions](https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal), which will actually install the Ingress Controller as a `NodePort` instead of a `LoadBalancer`. 

To do that simply `kubectl` the following: 

```
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/baremetal/deploy.yaml
```

### 2.2. Testing it

To test the Ingress Controller, let's create an Ingress to expose the `kapi-service` that we created in [Step 1](01.md)! 

Note, you might want to wait a bit to make sure that the NGINX Ingress Controller has been created before testing this. To make sure NGINX IC is ready, run ` kubectl get services -n ingress-nginx` and you should get this output (ports and cluster ips will probably be different in your case):
```
NAME                                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
ingress-nginx-controller             NodePort    10.103.26.76    <none>        80:31498/TCP,443:30416/TCP   3m17s
ingress-nginx-controller-admission   ClusterIP   10.110.155.10   <none>        443/TCP                      3m17s
```

You can create an `ingress.yaml` file containing the following: 

```
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: my-ingress
  annotations:
    # use the shared ingress-nginx
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  rules:
  - http:
      paths:
      - path: /api/base(/|$)(.*)
        backend:
            serviceName: kapi-service
            servicePort: 8080
```

And then just `kubectl apply` it! 

```
kubectl apply -f ingress.yaml
```

In case you don't feel like creating the yaml file, you can also use the one under `resources` ([github link here](https://github.com/nicolasances/k8s-gce-simple-way/blob/master/resources/ingress.yaml)):
```
kubectl apply -f https://raw.githubusercontent.com/nicolasances/k8s-gce-simple-way/master/resources/ingress.yaml
```

You're good! <br>
Now you can test it. To do that, ssh into any of the K8S nodes (`gcloud compute ssh <node-name>`) and execute the following: 

```
curl http://10.240.0.20:<nodeport>/api/base/status
```
Result: 
```
{"status":"running","msg":"All is fine man! I am up and running"}
```

Et voil√†! <br>
You're done with Step 2 and can now proceed to [Step 3: Creating an external load balancer ](03.md)!